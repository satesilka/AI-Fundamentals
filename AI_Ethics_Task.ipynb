{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Ethics. Practical Task\n",
        "\n",
        "## AI Risks Identification Tool\n",
        "\n",
        "Let's create an interactive and structured *AI Risks Identification Tool* that allows users to categorize the identified risks and provides a summary of the risks under each category. We'll use dictionaries and lists to organize the data.\n",
        "\n",
        "Below are the descriptions of the functions which will be used in the AI Risks Identification Tool:\n",
        "\n",
        "`get_risks_and_categories` - This function asks users to input the appropriate category of the potential risks associated with the usage of AI in everyday life. It prompts the user to enter risks and their corresponding categories iteratively until all the elements from `risks_list` will be passed. The risks and categories (entered by the user) are stored in a list of lists, where each category is 0 element of inner list, and the corresponding risks is stored as a 1 element of inner list (eg. `[[category0, risk0], [category1, risk1]], ...`).\n",
        "\n",
        "- Parameters: This function takes `risks_list` parameter.\n",
        "- Returns: This function returns `risks_categories` - a list of lists  containing the risks and categories.\n",
        "\n",
        "`identify_risks()` - This function allows users to identify and categorize potential risks associated with the usage of AI in everyday life. The risks and categories are stored in a dictionary, where each category is a key, and the corresponding risks are stored in a list under that key.\n",
        "\n",
        "- Parameters: This function takes `risks_categories` parameter.\n",
        "- Returns: This function returns a dictionary containing the categorized risks. The keys of the dictionary are the categories, and the values are lists of risks associated with each category.\n",
        "\n",
        "`display_risks_summary(risks)` - This function displays a summary of the identified AI risks under each category. It takes the categorized risks dictionary as input and prints the risks in a user-friendly format.\n",
        "\n",
        "- Parameters: `risks (dict)` - A dictionary containing categorized risks. The keys are the categories, and the values are lists of risks associated with each category.\n",
        "- Returns: This function does not return any value. It simply prints the summary of identified AI risks.\n",
        "\n",
        "The `identify_risks()` function organizes the entered risks into a dictionary to keep track of the different risk categories. The `display_risks_summary()` function then takes this dictionary as input and presents a clear summary of the identified AI risks under each category.\n",
        "\n",
        "These functions enable users to interactively explore and categorize AI risks, making it easier to comprehend the various challenges and concerns associated with the use of AI in everyday life.\n"
      ],
      "metadata": {
        "id": "J4wHqKTAknKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may use these sample data to test your code\n",
        "\n",
        "```\n",
        "Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\n",
        "Category: Privacy\n",
        "\n",
        "Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\n",
        "Category: Security\n",
        "\n",
        "Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
        "Category: Fairness\n",
        "\n",
        "Bias in AI algorithms may cause biased loan approvals for certain demographic groups.\n",
        "Category: Fairness\n",
        "\n",
        "AI system malfunctioning may result in incorrect medical diagnoses.\n",
        "Category: Safety\n",
        "\n",
        "AI-driven job automation may lead to unemployment and job displacement.\n",
        "Category: Social Impact\n",
        "```\n"
      ],
      "metadata": {
        "id": "Dyhl1aJivsnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/mehalyna/cooltest.git"
      ],
      "metadata": {
        "id": "gBCcpv4F0dJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba526ec-6b8c-4945-d516-a93eaa6dcd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/mehalyna/cooltest.git\n",
            "  Cloning https://github.com/mehalyna/cooltest.git to /tmp/pip-req-build-ije2wu2q\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mehalyna/cooltest.git /tmp/pip-req-build-ije2wu2q\n",
            "  Resolved https://github.com/mehalyna/cooltest.git to commit 630c96f2d3300782279879d5d13e6c1aaabf3c75\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from cooltest==26.22) (1.26.4)\n",
            "Building wheels for collected packages: cooltest\n",
            "  Building wheel for cooltest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cooltest: filename=cooltest-26.22-py3-none-any.whl size=5447 sha256=a571ce832f4b21d1086b15e38bd4d3408778cb3b950ce9a921def3dcd1a20fd6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9hqguy6d/wheels/5f/d0/08/46fba8323b078d91da2d05922a680d9728e94d53b453a8dd79\n",
            "Successfully built cooltest\n",
            "Installing collected packages: cooltest\n",
            "Successfully installed cooltest-26.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cooltest.test_cool_4 import *"
      ],
      "metadata": {
        "id": "nj87-lSz0eL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b5dcdf-331b-4634-bd23-43e4fefb0949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsDCRjINfw5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5add8a-6a3d-4999-a53b-e089bdbbcc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risk Task Passed\n",
            "\n",
            "Welcome to the AI Risks Identification Tool!\n",
            "Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\n",
            "Enter the category of each risk: \n",
            "A\n",
            "Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\n",
            "Enter the category of each risk: \n",
            "B\n",
            "Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
            "Enter the category of each risk: \n",
            "B\n",
            "\n",
            "AI Risks Summary:\n",
            "\n",
            "The identified categories and associated risks are as follows:\n",
            "\n",
            "Category: A\n",
            " - Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\n",
            "\n",
            "Category: B\n",
            " - Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\n",
            " - Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n"
          ]
        }
      ],
      "source": [
        "risks_list = [\n",
        "        \"Privacy concerns: AI-powered devices may collect personal data, raising concerns about how this data is stored and used.\",\n",
        "        \"Security vulnerabilities: AI systems could be susceptible to cyberattacks, leading to unauthorized access to personal information.\",\n",
        "        \"Bias in AI algorithms: AI algorithms might inadvertently perpetuate biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\",\n",
        "        #you may add more AI Risks to this list\n",
        "    ]\n",
        "\n",
        "\n",
        "def get_risks_and_categories(risks_list):\n",
        "    \"\"\"\n",
        "    Identify and categorize potential risks of using AI in everyday life.\n",
        "\n",
        "    Parameters:\n",
        "        risks_list (list): A list of potential risks and categories associated with AI usage.\n",
        "\n",
        "    Returns:\n",
        "        list: A list containing categorized risks.\n",
        "    \"\"\"\n",
        "\n",
        "    risk_categories = []\n",
        "    print(\"Welcome to the AI Risks Identification Tool!\")\n",
        "    for risk in risks_list:\n",
        "      print(risk)\n",
        "      category = input(\"Enter the category of each risk: \\n\")\n",
        "      risk_categories.append([category, risk])\n",
        "\n",
        "    return risk_categories\n",
        "\n",
        "@test_identify_risks\n",
        "def identify_risks(risks_categories):\n",
        "    \"\"\"\n",
        "    Identify and categorize potential risks of using AI in everyday life.\n",
        "\n",
        "    Parameters:\n",
        "        risks_categories (list): A list of potential risks and categories associated with AI usage.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing categorized risks.\n",
        "    \"\"\"\n",
        "    categorised_risks = {}\n",
        "    for risk in risks_categories:\n",
        "      category = risk[0]\n",
        "      risk_text = risk[1]\n",
        "      if category in categorised_risks:\n",
        "        categorised_risks[category].append(risk_text)\n",
        "      else:\n",
        "        categorised_risks[category] = [risk_text]\n",
        "\n",
        "    return categorised_risks\n",
        "\n",
        "def display_risks_summary(risks):\n",
        "    \"\"\"\n",
        "    Display a summary of identified risks under each category.\n",
        "\n",
        "    Parameters:\n",
        "        risks (dict): A dictionary containing categorized risks.\n",
        "    \"\"\"\n",
        "    print(\"\\nAI Risks Summary:\\n\")\n",
        "    print(\"The identified categories and associated risks are as follows:\")\n",
        "    for category, risks_list in risks.items():\n",
        "        print(f\"\\nCategory: {category}\")\n",
        "        for risk in risks_list:\n",
        "            print(f\" - {risk}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "risks_categories = get_risks_and_categories(risks_list)\n",
        "risks_data = identify_risks(risks_categories)\n",
        "display_risks_summary(risks_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvjlsm6in1Pu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}